\section{Preliminaries}
\label{sec:perliminary}

\begin{figure}[tbp]
	\hspace{0ex}
	\vspace{0ex}
	\centering
	\includegraphics[width = \textwidth]{fig/data_format}
	\caption{The data format of a tweet thread}
	\label{fig:data_format}
\end{figure}

In this section, we proceed to introduce the notations, problem definitions, and background knowledge of rumor tracking. The frequently used notations are summarized in Table~\ref{tab:notations}.

\subsection{Social Network Data}
\label{sec:social_network_data}
We use two benchmark datasets PHEME \cite{DBLP:conf/coling/KochkinaLZ18} and RumorEval \cite{DBLP:conf/semeval/EnayetE17}. Each dataset is a set of rumor events and each event is a set of tweet threads. The data format of a tweet thread is shown in Fig.~\ref{fig:data_format}. Each tweet thread is a tree structure. The root node corresponds to the source tweet and the branches correspond to a tweet sequence that includes retweets and comments. A tweet contains various types of features, including content, publication time, screen name, etc. The statistical details of PHEME and RumorEval are shown in Table \ref{tab:pheme} and Table \ref{tab:RumorEval}, respectively.

\begin{table}[tbp]
	\caption{Notation Summarization}
	\centering
	\label{tab:notations}
	\resizebox{\linewidth}{!}{
		\begin{tabular}{c|l|c|l}
			\hline
			\hline
			\textbf{Notation} & \textbf{Definition} & \textbf{Notation} & \textbf{Definition}\\
			\hline
			$T$ & the set of tweets &$t_n$ & a tweet\\
			\hline
			$C$ & the set of rumor events &$c_m$ & a rumor event\\
			\hline
			$y_F'$ & the output of FastText& $y_T'$ & the output of TextCNN\\
			\hline		
			$y_B'$ & the output of BiLSTM &$y_N'$ & the output of Naive Bayes\\
			\hline
			 $y_S'$ & the output of SVM-SGD & $X_b$ & a batch of samples\\
			\hline
			$R$ & the predicted result of \textcolor{blue}{RL-ERT} &$y'$& the output of \textcolor{blue}{RL-ERT}\\
			\hline
			$x \in R^{l*d}$ & a processed sample &$y \in N^m$ & a training label\\
			\hline
			$K_y$ & the set of all components outputs &$W_y$ & the weights of components in $K_y$\\
			\hline
			$A$& a set of actions & $S$& a set of states\\
			\hline
			$(s, a)$& a state-action tuple & $r$ = $R(s, a)$& a reward function on (s, a)\\
			\hline
			$\mu(\theta)$& a deterministic policy of reinforcement learning & $J(\mu_{\theta})$ & the performance objective on $\mu(\theta)$\\	
			\hline
			\hline				
		\end{tabular}
	}
\end{table}

\subsection{Problem Definition}
\label{sec:problem}
Let $T = \left\{t_1, t_2, ..., t_n \right\}$ denote a set of tweets and each tweet is denoted as $t_n$. Let $C = \left\{c_1, c_2, ... , c_m \right\}$ denote a set of rumor events and $c_m$ denotes a particular rumor event. Each tweet is assigned to only one rumor event. For each given tweet $t_n$, the goal of rumor tracking is to find the most relevant rumor event. In this work, we transform the binary rumor tracking problem (related/unrelated) into an \textcolor{blue}{$m-$way} classification problem. 

We conduct a preprocessing procedure to embed $T$ and $C$ into vectors. In preprocessing, a tweet $t_n \in T $ is padded to a fixed length $l$. Then, each word in the $l$-length tweet $t_n$ is embedded to a $d$-dimensional vector so that $t_n$ is transformed to a tensor $x^{(i)} \in R^{l*d}$. Also, we embed each event $c_m \in C$ to a \textcolor{blue}{one-hot vector $y^{(i)} \in N^m$}. By preprocessing, the dataset is transformed into: $$\left\{ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}),..., (x^{(n)}, y^{(n)}) \right\}, x^{(i)} \in R^{l*d}, y^{(i)} \in N^m $$ The goal is transformed to predict the $y^{(i)}$ for a given $x^{(i)}$. Existing work \cite{DBLP:conf/www/ChengNB20} links a testing sample $x^{(i)}$ with its source tweet. This setting disturbs the fairness of classification when predicting. In this work, we ensure that the branch and thread of a testing sample $x^{(i)}$ are unknown when predicting.

In a rumor event, the source tweets are collected by keywords such that the semantic similarity between the source tweets is usually high. We observe that this high similarity between the source tweets disturbs the classification performance. To verify our assumption, we conduct an experiment to train a rumor event classifier by using source tweets as input. The classification result suggests that the accuracy even reaches 100\%. Consequently, we cut down the link between the tweet and its source, and then process each tweet independently to obtain a convincing result.

\begin{figure}[htbp]
	\hspace{0ex}
	\vspace{0ex}
	\centering
	\includegraphics[width = \textwidth]{fig/structure}
	\caption{Architecture of RL-ERT}
	\label{fig:architecture}
\end{figure} 

\subsection{Basic Models for Text Classification}
\label{sec:deeplearning_model} 
In this section, we proceed to introduce some basic text classification models. These models are components that form the ensemble model. The structure of the ensemble model is shown in Fig~\ref{fig:architecture}.

\subsubsection{Non-Deep Learning based Models}
\textbf{Naive Bayes} \cite{DBLP:journals/ml/DomingosP97} is widely adopted for short text classification which shows good performance. It assumes that all input variables are independent of each other. By multiplying the conditional probabilities of each word, it achieves satisfied performances on text classification task with only small quantities of parameters. The procedure of Naive Bayes is formalized as follows:
\begin{align}\label{eq:nb}
y_{N_{i}}' &= \frac{P(y_i)\prod_{j = 0}^d P(x_j|y_i)}{\prod_{j = 0}^d P(x_j)},\\
y_N' &= [y_{N_{1}}',y_{N_{2}}',..., y_{N_{i}}'],
\end{align}
where $x_j$ is a component of $x$, corresponding to a word in tweet.  $y_i$ is a component of training sample $y$. $y_{N_{i}}'$ is a component of $y_N'$, representing the probability of a classification. \textcolor{blue}{$[\cdot]$ is concatenate operation. Naive Bayes model is stable and efficient, which guarantees the lower bound of classification.} We choose Naive Bayes as a component of RL-ERT and $y_N'$ is the final output.

\textbf{SVM-SGD} \cite{avriel2003nonlinear} \textcolor{blue}{In RL-ERT, we choose soft-margin based linear Support Vector Machine (SVM) with Stochastic gradient descent (SGD) as a sub-model. Besides, we use a one-vs-all (OVA) strategy to transfer it from binary classifier to $m$-way classifier. Stochastic gradient descent (SGD) is an optimizer in machine learning, which is widely adopted in text classification with large-scaled corpus. SVM-SGD based machine learning models are trained on large scale datasets by updating parameters on each single input. We denote the procedure of SVM-SGD model as $S(\cdot)$, and the output of SVM-SGD model is}:
\begin{equation}\label{eq:sgd}
y_S' = S(TFIDF(x)),
\end{equation}
where TFIDF is Term Frequency-Inverse Document Frequency. \textcolor{blue}{The input $x$ for SVM-SGD is processed by TFIDF on the whole corpus of tweets. The output $y_S'$ is the predicted result. SVM-SGD has good robustness, which is proper as a component.  Finally, we choose the SVM-SGD model as the component of RL-ERT.}

\subsubsection{Deep Learning based Models}

\textbf{FastText} \cite{DBLP:journals/tacl/BojanowskiGJM17, DBLP:journals/corr/JoulinGBDJM16, DBLP:conf/eacl/GraveMJB17} is an extension of the skip-gram model introduced by Mikolov et al. \cite{DBLP:conf/nips/MikolovSCCD13}. The main difference between FastText and skip-gram is that the predicted target of FastText is a classification label rather than a middle word. Also, FastText adopts hierarchical softmax to deal with the large corpus and vocabulary dictionary. With the help of these optimizations, FastText classifies large amounts of texts in a short time. We choose FastText as a component of RL-ERT and its output is denoted as $y_F'$.

\textbf{BiLSTM} \cite{DBLP:journals/neco/HochreiterS97} is Bi-directional Long Short-Term Memory, which consists of a forward LSTM and a backward LSTM. LSTM effectively learns the long term dependency of sequential data. We usually treat BiLSTM as an evolution of LSTM and it is suitable for text data. The details of LSTM are following:
\begin{align}\label{eq:lstm}
i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i),\\
f_t &= \sigma(W_f \cdot [h_{t-1}, x_t]),\\
\widetilde{C_t} &= tanh(W_{\tilde{C_t}} \cdot [r_t C_{t-1}, x_t]  + b_C),\\
C_t &= (1-f_t) C_{t-1} + f_t \widetilde{C_t},\\
h_t &=o_t \* \tanh(C_t),\\
o_t &=  \sigma(W_o \cdot h_t),\\
y_B^{'} &= [o_{t,f}, o_{t,b}],
\end{align}
\textcolor{blue}{where $x_t$ is the input at time step $t$. LSTM consists of three gates: forget gate $f_t$, input gate $i_t$, and output gate $o_t$. Also, it has two memories: long-term memory $C_t$ and short-memory $h_t$. Finally, we use forward and backward input sequence to generate forward output $o_{t,f}$ and backward output $o_{t,f}$, respectively. The final output of BiLSTM is denoted as $y_B^{'}$, which is concatenated by $o_{t,f}$ and $o_{t,f}$. $[\cdot]$ is the concatenate operation. BiLSTM captures the long-term dependency of rumor tweets, which is possible to promote the performance of RL-ERT. Therefore, we choose BiLSTM as a component of RL-ERT.}

\textbf{TextCNN} \cite{DBLP:conf/emnlp/Kim14} uses multiple convolutional filters with different sizes to capture N-gram features. Compared to RNN based models, TextCNN reaches convergence faster due to the parallel computation. The tweets are usually short texts (within 140 words) with sparse semantic. Consequently, CNN based models are more suitable than RNN based models for tweets classification because tweets are usually treated as a bag of words. We choose TextCNN as one of the components of \textcolor{blue}{RL-ERT}. The brief procedure of TextCNN is shown as follows,
\begin{align}\label{eq:tcnn}
V_x &= Embedding(x), \\
m_3 &= maxpooling(ConV_3(V_x)),\\
m_4 &= maxpooling(ConV_4(V_x)),\\
m_5 &= maxpooling(ConV_5(V_x)),\\
y_T' &= flatten(concat(m_3, m_4, m_5)),
\end{align}

where the $Embedding(\cdot)$ is the embedding layer, and $m_i (i = 3,4,5)$ is the output of different convolutional filter. \textcolor{blue}{The max-pooling reduces the amount of parameters and the model size of TextCNN. By concatenating and flattening, TextCNN generates the output that is denoted as $y_T'$. TextCNN has a low consume of computation, which is chosen as a component of RL-ERT.} 

\subsection{Deterministic Policy Gradient Algorithm}
Deterministic Policy Gradient Algorithm (DPG) \cite{DBLP:conf/icml/SilverLHDWR14} is a policy-based reinforcement learning algorithm. DPG assumes the action space is continuous and generates actions efficiently with deterministic policy. Therefore, DPG is suitable for weight tuning. As a reinforcement learning based model, DPG includes: \textbf{Action} $A$, \textbf{State} $S$, and \textbf{Reward} $R(S,A)$. The policy gradient of DPG is as follows:
\begin{equation}
\nabla_\theta J(\mu_\theta) =  \mathbb{E}_{s \sim \rho^\mu} \left[\nabla_\theta \mu_\theta (s)\nabla_a Q^\mu (s, a) |_{a = \mu_\theta(s)}  \right],
\end{equation}
where $\mu_\theta$ is the deterministic policy function with parameter $\theta$ and $Q^\mu(s, a)$ is the action-value function on $\mu$. For a given $s$, the policy function generates an $a$, which is denoted as $a=\mu_\theta(s)$. $J(\cdot)$ is the performance objective.
